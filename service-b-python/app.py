#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Service B - ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸ÑĞ° (Python Flask + JFR Ğ¸Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ)
Ğ›Ğ 3: ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
"""

from flask import Flask, request, jsonify
import time
import json
import copy
from collections import defaultdict
from typing import List, Dict, Tuple
import psutil
import os

app = Flask(__name__)

# === Ğ”ĞĞĞĞ«Ğ• Ğ¤Ğ˜Ğ›Ğ¬ĞœĞĞ’ ===
MOVIES = [
    {"id": 1, "title": "The Shawshank Redemption", "year": 1994, "genre": "Drama", "rating": 9.3, "description": "Two imprisoned men bond over a number of years..."},
    {"id": 2, "title": "The Godfather", "year": 1972, "genre": "Crime", "rating": 9.2, "description": "The aging patriarch of an organized crime dynasty..."},
    {"id": 3, "title": "The Dark Knight", "year": 2008, "genre": "Action", "rating": 9.0, "description": "When the menace known as the Joker wreaks havoc..."},
    {"id": 4, "title": "Pulp Fiction", "year": 1994, "genre": "Crime", "rating": 8.9, "description": "The lives of two mob hitmen, a boxer, a gangster..."},
    {"id": 5, "title": "Forrest Gump", "year": 1994, "genre": "Drama", "rating": 8.8, "description": "The presidencies of Kennedy and Johnson unfold..."},
    {"id": 6, "title": "Inception", "year": 2010, "genre": "Action", "rating": 8.8, "description": "A thief who steals corporate secrets through dream-sharing..."},
    {"id": 7, "title": "Fight Club", "year": 1999, "genre": "Drama", "rating": 8.8, "description": "An insomniac office worker and a devil-may-care soap maker..."},
    {"id": 8, "title": "The Matrix", "year": 1999, "genre": "Action", "rating": 8.7, "description": "A computer programmer discovers that reality as he knows it..."},
    {"id": 9, "title": "Goodfellas", "year": 1990, "genre": "Crime", "rating": 8.7, "description": "The story of Henry Hill and his life in the mob..."},
    {"id": 10, "title": "The Silence of the Lambs", "year": 1991, "genre": "Thriller", "rating": 8.6, "description": "A young FBI cadet must receive help from an incarcerated..."},
    {"id": 11, "title": "Saving Private Ryan", "year": 1998, "genre": "Action", "rating": 8.6, "description": "Following the Normandy Landings, a group of U.S. soldiers..."},
    {"id": 12, "title": "Jurassic Park", "year": 1993, "genre": "Action", "rating": 8.2, "description": "A pragmatic paleontologist touring an almost complete theme park..."},
    {"id": 13, "title": "The Avengers", "year": 2012, "genre": "Action", "rating": 8.0, "description": "Earth's mightiest heroes must come together..."},
    {"id": 14, "title": "Avatar", "year": 2009, "genre": "Action", "rating": 7.9, "description": "A paraplegic Marine dispatched to the moon Pandora..."},
    {"id": 15, "title": "Interstellar", "year": 2014, "genre": "Drama", "rating": 8.6, "description": "A team of explorers travel through a wormhole in space..."},
]

# === Ğ¡Ğ§ĞĞ¢Ğ§Ğ˜ĞšĞ˜ ĞŸĞ ĞĞ¤Ğ˜Ğ›Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ¯ ===
profiling_data = {
    'inefficient': {
        'calls': 0,
        'total_time': 0.0,
        'measurements': [],
        'total_memory': 0.0,
    },
    'optimized': {
        'calls': 0,
        'total_time': 0.0,
        'measurements': [],
        'total_memory': 0.0,
    }
}

# === ĞĞ•ĞĞŸĞ¢Ğ˜ĞœĞ˜Ğ—Ğ˜Ğ ĞĞ’ĞĞĞĞĞ¯ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ¯ (Hot Spots) ===
def get_top_n_by_genre_inefficient(genre: str, limit: int) -> Tuple[List[Dict], float, float]:
    """
    ĞĞµĞ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ñ ÑĞ²Ğ½Ñ‹Ğ¼Ğ¸ hot spots:
    - HOT SPOT 1: Ğ”ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ°ÑÑĞ¸Ğ²Ğ° 3 Ñ€Ğ°Ğ·Ğ°
    - HOT SPOT 2: ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ 300 ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ²Ğ¼ĞµÑÑ‚Ğ¾ 100
    - HOT SPOT 3: Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· 300 ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
    - HOT SPOT 4: ĞŸĞµÑ€Ğ²Ğ°Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° (Ğ¿Ğ¾ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ)
    - HOT SPOT 5: Ğ’Ñ‚Ğ¾Ñ€Ğ°Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° (Ğ¿Ğ¾ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ) - Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ¿ĞµÑ€Ğ²ÑƒÑ
    """
    start_time = time.perf_counter()
    process = psutil.Process(os.getpid())
    start_memory = process.memory_info().rss / 1024 / 1024  # MB

    # HOT SPOT 1: Ğ”ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ°ÑÑĞ¸Ğ²Ğ° 3 Ñ€Ğ°Ğ·Ğ° (Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğµ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ)
    copy1 = copy.deepcopy(MOVIES)
    copy2 = copy.deepcopy(MOVIES)
    copy3 = copy.deepcopy(MOVIES)

    # HOT SPOT 2: ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€Ñ‘Ñ… ĞºĞ¾Ğ¿Ğ¸Ğ¹ (300 ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ²Ğ¼ĞµÑÑ‚Ğ¾ 100)
    merged = copy1 + copy2 + copy3

    # HOT SPOT 3: Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· 300 ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
    filtered = [m for m in merged if m['genre'] == genre]

    # HOT SPOT 4: ĞŸĞµÑ€Ğ²Ğ°Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° (Ğ¿Ğ¾ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ)
    sorted_by_title = sorted(filtered, key=lambda m: m['title'])

    # HOT SPOT 5: Ğ’Ñ‚Ğ¾Ñ€Ğ°Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° (Ğ¿Ğ¾ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ) - Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ¿ĞµÑ€Ğ²ÑƒÑ, Ğ½ĞµÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾
    sorted_by_rating = sorted(sorted_by_title, key=lambda m: m['rating'], reverse=True)

    # HOT SPOT 6: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°
    result = sorted_by_rating[:limit]

    end_time = time.perf_counter()
    end_memory = process.memory_info().rss / 1024 / 1024
    
    elapsed_ms = (end_time - start_time) * 1000
    allocated_mb = end_memory - start_memory

    return result, elapsed_ms, allocated_mb


# === ĞĞŸĞ¢Ğ˜ĞœĞ˜Ğ—Ğ˜Ğ ĞĞ’ĞĞĞĞĞ¯ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ¯ (Best Practices) ===
def get_top_n_by_genre_optimized(genre: str, limit: int) -> Tuple[List[Dict], float, float]:
    """
    ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ:
    - ĞĞ´Ğ¸Ğ½ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ (filter â†’ sort â†’ slice)
    - ĞĞ´Ğ½Ğ° ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° (Ğ¿Ğ¾ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ñƒ)
    - ĞĞ¸ĞºĞ°ĞºĞ¸Ñ… Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… ĞºĞ¾Ğ¿Ğ¸Ğ¹
    - Ğ›ĞµĞ½Ğ¸Ğ²Ğ¾Ğµ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ
    """
    start_time = time.perf_counter()
    process = psutil.Process(os.getpid())
    start_memory = process.memory_info().rss / 1024 / 1024

    # ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº:
    result = (
        sorted(
            [m for m in MOVIES if m['genre'] == genre],
            key=lambda m: m['rating'],
            reverse=True
        )[:limit]
    )

    end_time = time.perf_counter()
    end_memory = process.memory_info().rss / 1024 / 1024
    
    elapsed_ms = (end_time - start_time) * 1000
    allocated_mb = end_memory - start_memory

    return result, elapsed_ms, allocated_mb


# === REST API ENDPOINTS ===

@app.route('/recommendations', methods=['GET'])
def recommendations():
    """
    Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¹Ğ½Ñ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹ Ñ„Ğ¸Ğ»ÑŒĞ¼Ğ¾Ğ².
    
    ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹:
    - genre: Ğ¶Ğ°Ğ½Ñ€ (default: Action)
    - limit: ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² (default: 10)
    - mode: Ñ€ĞµĞ¶Ğ¸Ğ¼ (inefficient Ğ¸Ğ»Ğ¸ optimized, default: optimized)
    """
    genre = request.args.get('genre', 'Action')
    limit = int(request.args.get('limit', 10))
    mode = request.args.get('mode', 'optimized')

    if mode == 'inefficient':
        result, elapsed_ms, allocated_mb = get_top_n_by_genre_inefficient(genre, limit)
        profiling_data['inefficient']['calls'] += 1
        profiling_data['inefficient']['total_time'] += elapsed_ms
        profiling_data['inefficient']['measurements'].append(elapsed_ms)
        profiling_data['inefficient']['total_memory'] += allocated_mb
    else:
        result, elapsed_ms, allocated_mb = get_top_n_by_genre_optimized(genre, limit)
        profiling_data['optimized']['calls'] += 1
        profiling_data['optimized']['total_time'] += elapsed_ms
        profiling_data['optimized']['measurements'].append(elapsed_ms)
        profiling_data['optimized']['total_memory'] += allocated_mb

    print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {mode.upper():12s} | Genre: {genre:10s} | Limit: {limit:3d} | Time: {elapsed_ms:8.2f}ms | Memory: {allocated_mb:8.2f}MB")

    return jsonify({
        'genre': genre,
        'limit': limit,
        'mode': mode,
        'result': result,
        'response_time_ms': round(elapsed_ms, 2),
        'allocated_mb': round(allocated_mb, 2),
        'count': len(result)
    })


@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({'status': 'ok'})


@app.route('/profiling-report', methods=['GET'])
def profiling_report():
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
    
    inefficient_avg = (
        profiling_data['inefficient']['total_time'] / profiling_data['inefficient']['calls']
        if profiling_data['inefficient']['calls'] > 0
        else 0
    )
    
    optimized_avg = (
        profiling_data['optimized']['total_time'] / profiling_data['optimized']['calls']
        if profiling_data['optimized']['calls'] > 0
        else 0
    )
    
    improvement = (
        ((inefficient_avg - optimized_avg) / inefficient_avg * 100)
        if inefficient_avg > 0
        else 0
    )

    inefficient_measurements = profiling_data['inefficient']['measurements']
    optimized_measurements = profiling_data['optimized']['measurements']

    return jsonify({
        'summary': {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'profiling_enabled': True
        },
        'inefficient': {
            'calls': profiling_data['inefficient']['calls'],
            'avg_response_time_ms': round(inefficient_avg, 2),
            'total_allocations_mb': round(profiling_data['inefficient']['total_memory'], 2),
            'min_time_ms': round(min(inefficient_measurements), 2) if inefficient_measurements else 0,
            'max_time_ms': round(max(inefficient_measurements), 2) if inefficient_measurements else 0,
        },
        'optimized': {
            'calls': profiling_data['optimized']['calls'],
            'avg_response_time_ms': round(optimized_avg, 2),
            'total_allocations_mb': round(profiling_data['optimized']['total_memory'], 2),
            'min_time_ms': round(min(optimized_measurements), 2) if optimized_measurements else 0,
            'max_time_ms': round(max(optimized_measurements), 2) if optimized_measurements else 0,
        },
        'improvement': {
            'response_time_improvement_percent': round(improvement, 1),
            'estimated_speedup': round(inefficient_avg / max(optimized_avg, 0.001), 1) if optimized_avg > 0 else 0
        }
    })


@app.route('/profiling-reset', methods=['POST'])
def profiling_reset():
    """Ğ¡Ğ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
    global profiling_data
    profiling_data = {
        'inefficient': {'calls': 0, 'total_time': 0.0, 'measurements': [], 'total_memory': 0.0},
        'optimized': {'calls': 0, 'total_time': 0.0, 'measurements': [], 'total_memory': 0.0}
    }
    return jsonify({'status': 'profiling data reset'})


# === Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ¡Ğ•Ğ Ğ’Ğ•Ğ Ğ ===
if __name__ == '__main__':
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   Service B - ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸ÑĞ° (Python)    â•‘
â•‘              Ñ Ğ¸Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸ĞµĞ¹ Java JFR                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ Ğ¡ĞµÑ€Ğ²ĞµÑ€ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ Ğ½Ğ° http://localhost:8081

ğŸ“Š Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¹Ğ½Ñ‚Ñ‹:
  â€¢ GET /recommendations?genre=Action&limit=10&mode=inefficient|optimized
  â€¢ GET /health
  â€¢ GET /profiling-report
  â€¢ POST /profiling-reset

ğŸ”¬ ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² PowerShell:
  
  ĞĞµĞ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ (500 Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²):
  for ($i=1; $i -le 500; $i++) { 
    curl "http://localhost:8081/recommendations?genre=Action&limit=10&mode=inefficient"
  }

  ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ (500 Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²):
  for ($i=1; $i -le 500; $i++) { 
    curl "http://localhost:8081/recommendations?genre=Action&limit=10&mode=optimized"
  }

  ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ° Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:
  curl http://localhost:8081/profiling-report | ConvertFrom-Json | ConvertTo-Json -Depth 10

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    app.run(host='0.0.0.0', port=8081, debug=False, use_reloader=False)
